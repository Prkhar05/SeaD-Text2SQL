{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saksh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_erosion(schema: str, sql: str,p_drop:int,p_add:int,schemas) -> Tuple[str, str]:\n",
    "        sql_cols = re.findall(r'<col\\d+>', sql)\n",
    "        tables = re.findall(r'<table\\d+>\\[(.*?)\\]\\s\\{(.*?)\\}', schema)\n",
    "        table_nums = re.findall(r'<col(\\d+)>', schema)\n",
    "        table_nums = list(map(int, table_nums))\n",
    "        max_table_num = max(table_nums)+1\n",
    "        modified_tables = []\n",
    "\n",
    "        for table in tables:\n",
    "            modified_table=[]\n",
    "            table_name=table[0]\n",
    "            columns = re.findall(r'<col\\d+>\\[.*?\\]:\\[.*?\\]', table[1])\n",
    "            \n",
    "            # Permutation: Randomly reorder the columns\n",
    "            random.shuffle(columns)\n",
    "            \n",
    "            # Removal: Randomly remove columns based on the drop probability\n",
    "            for col in columns:\n",
    "                if random.random() < p_drop:\n",
    "                    columns.remove(col)\n",
    "                    removed_col = re.search(r'<col\\d+>', col).group(0)\n",
    "                    sql_cols = list(map(lambda x: x.replace(removed_col, \"<unk>\"), sql_cols))\n",
    "                    sql = sql.replace(removed_col,\"<unk>\")\n",
    "                    \n",
    "                      \n",
    "                 \n",
    "            \n",
    "            # Addition: Add columns from other schemas based on the add probability\n",
    "            if random.random() < p_add:\n",
    "                extra_table = random.choice(schemas)\n",
    "                extra_columns = re.findall(r'\\[.*?\\]:\\[.*?\\]', extra_table)\n",
    "                \n",
    "                added_cols= random.sample(extra_columns, k=min(len(extra_columns), 1))\n",
    "                for col in added_cols:\n",
    "                    modified_col = f'<col{max_table_num}>{col}'\n",
    "                    max_table_num += 1\n",
    "                    columns.append(modified_col)\n",
    "            \n",
    "            \n",
    "            modified_table.append(table_name)\n",
    "            modified_table.append(\" \".join(columns))\n",
    "            modified_tables.append(modified_table)\n",
    "        \n",
    "        modified_schema = \" \".join([f\"<table{i}>[{table[0]}] {{{table[1]}}}\" for i, table in enumerate(modified_tables)])\n",
    "        \n",
    "        return modified_schema, sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"prkhar05/SeaD_smalltrain\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table0>[table_name_44] { <col0>[numer_of_jamaicans_granted_british_citizenship]:[INTEGER] <col1>[year]:[VARCHAR] <col2>[registration_of_a_minor_child]:[VARCHAR]  } \n",
      "SELECT SUM( `<col0>` ) FROM `<table0>` WHERE `<col1>` = 2004 AND `<col2>` > 640\n"
     ]
    }
   ],
   "source": [
    "schema = ds[0]['schema']\n",
    "print(schema)\n",
    "sql = ds[0]['query']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text(ds):\n",
    "    for item in ds:\n",
    "        return item['schema'] + \" \" + item['question'] + \" \" +  item['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table0>[table_name_44] { <col0>[numer_of_jamaicans_granted_british_citizenship]:[INTEGER] <col1>[year]:[VARCHAR] <col2>[registration_of_a_minor_child]:[VARCHAR]  }   Tell me the sum of number of jamaicans given british citizenship for 2004 and registration of a minor child more than 640\\n SELECT SUM( `<col0>` ) FROM `<table0>` WHERE `<col1>` = 2004 AND `<col2>` > 640'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = get_all_text(ds)\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_drop = 0.2\n",
    "p_add = 0.4\n",
    "schemas = ds['train']['schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table0>[table_name_44] {<col0>[numer_of_jamaicans_granted_british_citizenship]:[INTEGER] <col1>[year]:[VARCHAR]}\n",
      "SELECT SUM( `<col0>` ) FROM `<table0>` WHERE `<col1>` = 2004 AND `<unk>` > 640\n"
     ]
    }
   ],
   "source": [
    "modified_schema , modified_sql = apply_erosion(schema,sql,p_drop,p_add,schemas)\n",
    "print(modified_schema)\n",
    "print(modified_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT SUM( `<col0>` ) FROM `<table0>` WHERE `<col1>` = 2004 AND `<col2>` > 640'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(sql: str) -> str:\n",
    "    # Define regex patterns for <col>, <table>, and numbers\n",
    "    col_pattern = r'<col\\d+>'\n",
    "    table_pattern = r'<table\\d+>'\n",
    "    number_pattern = r'\\b\\d+\\b'  # Matches standalone numbers\n",
    "\n",
    "    # Function to shuffle a list of items preserving non-matching items\n",
    "    def shuffle_entities(entities, tokens):\n",
    "        shuffled_entities = entities[:]\n",
    "        random.shuffle(shuffled_entities)\n",
    "        result = []\n",
    "        index = 0\n",
    "        for token in tokens:\n",
    "            if token in entities:\n",
    "                result.append(shuffled_entities[index])\n",
    "                index += 1\n",
    "            else:\n",
    "                result.append(token)\n",
    "        return result\n",
    "\n",
    "    # Tokenize SQL by spaces\n",
    "    split_pattern = r'\\s+|([`()\"\\'\\[\\]])'\n",
    "    tokens = re.split(split_pattern,sql)\n",
    "    tokens = filter(None, tokens)\n",
    "\n",
    "    # Collect all <col>, <table>, and number entities\n",
    "    entities_to_shuffle = []\n",
    "\n",
    "    cols = re.findall(col_pattern,sql)\n",
    "    tables = re.findall(table_pattern,sql)\n",
    "    nums = re.findall(number_pattern,sql)\n",
    "\n",
    "    entities_to_shuffle = cols + tables + nums\n",
    "    \n",
    "    # Shuffle entities while preserving the rest of the tokens\n",
    "    shuffled_tokens = shuffle_entities(entities_to_shuffle, tokens)\n",
    "    # Reconstruct SQL query\n",
    "    shuffled_sql = \" \".join(shuffled_tokens)\n",
    "    return shuffled_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT SUM ( ` 2004 ` ) FROM ` <table0> ` WHERE ` <col1> ` = 640 AND ` <col0> ` > <col2>'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_sql = shuffle(sql)\n",
    "shuffled_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
